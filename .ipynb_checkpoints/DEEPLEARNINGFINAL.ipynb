{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-73vB5XOe-rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Libraries"
      ],
      "metadata": {
        "id": "lfaRdggkq49S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #to work with the operating system\n",
        "import shutil #to save files if needed\n",
        "import numpy as np #to create numpy array for manipulating image and storing\n",
        "from PIL import Image, ImageDraw #for displaying image, opening image and drawing on image\n",
        "import matplotlib.pyplot as plt #to display grid\n",
        "import json #to easily read json file\n",
        "import random #to pick random image\n",
        "import tensorflow as tf #to load up tensors of image and masks\n",
        "import keras #to create and train the deep learning model\n",
        "from keras import layers #to work with the layers of the model\n",
        "import multiprocessing #to allow for multiple gpus to be use for speed\n",
        "# loading dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "UvZ8VyjceGMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do this first because can't do later\n",
        "def configure_tensorflow_gpu():\n",
        "    # turn on multiple cores.  Once started you cannot change it.\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(num_cores)\n",
        "    # tf.config.threading.set_inter_op_parallelism_threads(2)\n",
        "    # Make sure it is taking advantage of the gpu instead of cpu.  Faster\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu,True)\n",
        "        except RuntimeError as e:\n",
        "            print(f\"no gpu from {e}\")\n",
        "    else:\n",
        "        print(\"no gpu\")\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "    return num_cores"
      ],
      "metadata": {
        "id": "fegzCydtyje7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configure_tensorflow_gpu()"
      ],
      "metadata": {
        "id": "JJCc1cHUyrYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrCJs5x73xON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_path(img_num):\n",
        "    img_path = f\"img{img_num}.png\"\n",
        "    # this is where I stored it, but you might need to change, and we will have to get file structure figured out before sending\n",
        "    img_path = os.path.join(\"../final_project/google_collab_imgs\", img_path)\n",
        "\n",
        "    return img_path"
      ],
      "metadata": {
        "id": "3NNa4XnlEqG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Design & Implementation\n"
      ],
      "metadata": {
        "id": "a19N3Jiark7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Process"
      ],
      "metadata": {
        "id": "yaWUuW8BqgeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# created smaller function to help just get the json file.  I used hardcoded values of 293 images with 2 augmented images each\n",
        "def get_json_path(img_num):\n",
        "    img_num = img_num if img_num < 294 else img_num - 293 if img_num < 587 else img_num - 586\n",
        "    json_name = f\"img{img_num}.json\"\n",
        "    json_path = os.path.join(\"../final_project/google_collab_imgs\",json_name)\n",
        "    return json_path"
      ],
      "metadata": {
        "id": "lnQCAo2Wqyq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also initally did this step so we could look at the augmentations and observe testing, however, I know there is some functionality where the model will\n",
        "# do this automatically, but wanted to do it ourselves\n",
        "def augment_img(img_num):\n",
        "    img_path = get_image_path(img_num)\n",
        "    img = Image.open(img_path)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img_array = np.array(img)\n",
        "    xy = get_x_y_coordinates_from_json(img_num)\n",
        "    img_array_augmented = random_img_augmentation(img_array, xy)\n",
        "    return img_array_augmented\n"
      ],
      "metadata": {
        "id": "MAdyEKVLzXg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_y_coordinates_from_json(img_num):\n",
        "    # get_json_path is hardcoed to 293 only 3 times\n",
        "    json_path = get_json_path(img_num)\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        points = data['shapes'][0]['points']\n",
        "        avg_x = sum([point[0] for point in points]) / len(points)\n",
        "        avg_y = sum([point[1] for point in points]) / len(points)\n",
        "    return [avg_x, avg_y]"
      ],
      "metadata": {
        "id": "aiP-TsQsjsxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also initally did this step so we could look at the augmentations and observe testing, can do automatically but we wanted to do ourselves\n",
        "def augment_img(img_num):\n",
        "    img_path = get_image_path(img_num)\n",
        "    img = Image.open(img_path)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img_array = np.array(img)\n",
        "    xy = get_x_y_coordinates_from_json(img_num)\n",
        "    img_array_augmented = random_img_augmentation(img_array, xy)\n",
        "    return img_array_augmented\n",
        "\n"
      ],
      "metadata": {
        "id": "275d-RK7_DUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_img_augmentation(img, xy):\n",
        "    # Randomly choose a transformation from the ones below.  We also thought about flipping and rotating, but our actual bills\n",
        "    # were already flipped and rotated sufficiently with the images of the bills in all kinds of positions, we didn't think this\n",
        "    # would provide enough difference.  Each value below was tweaked through trial and error to find sufficient blurrings/lightings/darkenings\n",
        "    # to truly work the model but not too much to leave it completely unreadable.\n",
        "    # The choice of adding holes had too many of the images with the holes completely away from the actual bills, so the choice was made\n",
        "    # to include the x and y coordinates of the money to center the holes around where the money was located to make the holes more impactful\n",
        "    choice = np.random.choice([ 'darken','lighten', 'blur', 'add_holes'])\n",
        "    from PIL import Image, ImageFilter\n",
        "    pil_img = Image.fromarray(img)\n",
        "    if choice == 'darken':\n",
        "        # found a good level here.  0.9 couldn't see any difference.  Wanted it to be something worthwhile\n",
        "        factor = np.random.uniform(0.3, 0.1)\n",
        "        pil_img = pil_img.point(lambda p: p * factor)\n",
        "    elif choice == 'lighten':\n",
        "        factor = np.random.uniform(2, 4)\n",
        "        pil_img = pil_img.point(lambda p: min(255, p * factor))\n",
        "    elif choice == 'blur':\n",
        "        blur_val = np.random.uniform(5, 13)\n",
        "        pil_img = pil_img.filter(ImageFilter.GaussianBlur(radius=blur_val))\n",
        "    elif choice == 'add_holes':\n",
        "        avg_x, avg_y = xy\n",
        "        draw = ImageDraw.Draw(pil_img)\n",
        "        num_holes = np.random.randint(3, 10)\n",
        "        for _ in range(num_holes):\n",
        "            #\n",
        "            x1 = int(avg_x) + np.random.randint(-400, 400)\n",
        "            y1 = int(avg_y) + np.random.randint(-400, 400)\n",
        "            x2 = x1 + np.random.randint(50, 200)\n",
        "            y2 = y1 + np.random.randint(50, 200)\n",
        "            draw.rectangle([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "    return np.array(pil_img)"
      ],
      "metadata": {
        "id": "OGFoN5ouz3Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binary masks with the img_number coming in, the label_array of what we want masked crop, money, one, five, ten, etc\n",
        "# bill_imagined wasn't working well here.\n",
        "def create_binary_mask_from_json(img_num, label_array, img_shape):\n",
        "    # so we don't have to create so many json files\n",
        "    json_path = get_json_path(img_num)\n",
        "    width, height = img_shape\n",
        "\n",
        "    masks  = np.zeros((len(label_array), height, width), dtype = np.uint8)\n",
        "    with open(json_path, 'r') as f:\n",
        "        tags = json.load(f)\n",
        "\n",
        "    for i, label in enumerate(label_array):\n",
        "        temp_img = Image.new('L', (width,height),0)\n",
        "        draw = ImageDraw.Draw(temp_img)\n",
        "\n",
        "        for shape in tags['shapes']:\n",
        "            if shape['label'] == label:\n",
        "                points = shape['points']\n",
        "\n",
        "                if len(points) == 2:\n",
        "                    draw.rectangle([tuple(points[0]), tuple(points[1])], fill = 255)\n",
        "                else:\n",
        "                    draw.polygon([tuple(point) for point in points], fill = 255)\n",
        "        temp_array = np.array(temp_img)\n",
        "        masks[i] = np.maximum(masks[i], temp_array)\n",
        "    return masks"
      ],
      "metadata": {
        "id": "fEhwql7Dz6Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_segmentation_dataset(label_array = [\"money\"],iters = 2, target_size = (256,256)):\n",
        "    images = []\n",
        "    masks = []\n",
        "    imgs_processed = 0\n",
        "\n",
        "    for img_num in range(1,294):\n",
        "        json_path = get_json_path(img_num)\n",
        "        img_path = get_image_path(img_num)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            img_size = image.size\n",
        "            image_resized = np.array(image.resize(target_size)) / 255.0\n",
        "            mask_arrays = create_binary_mask_from_json(img_num,label_array, img_size)\n",
        "\n",
        "            # resize all masks and keep them separate for multi-channel approach\n",
        "            processed_masks = []\n",
        "            for mask_array in mask_arrays:\n",
        "                mask_resized = np.array(Image.fromarray(mask_array).resize(target_size, Image.NEAREST))\n",
        "                mask_resized = (mask_resized > 127).astype(np.float32)\n",
        "                mask_resized = np.expand_dims(mask_resized, axis=-1)\n",
        "                processed_masks.append(mask_resized)\n",
        "\n",
        "            # Create multi-channel mask: concatenates along channel dimension\n",
        "            combined_mask = np.concatenate(processed_masks, axis=-1)  # Shape: (256, 256, num_labels)\n",
        "            for img_augmenting in range(2):\n",
        "                augmented_img_array = augment_img(img_num)\n",
        "                image_augmented = Image.fromarray(augmented_img_array)\n",
        "                image_augmented_resized = np.array(image_augmented.resize(target_size)) / 255.0\n",
        "                images.append(image_augmented_resized)\n",
        "                masks.append(combined_mask)  # SAME JSON because SAME IMAGE JUST AUGMENTED\n",
        "                imgs_processed += 1\n",
        "            imgs_processed += 1\n",
        "            images.append(image_resized)\n",
        "            masks.append(combined_mask)  # SAME JSON because SAME IMAGE JUST AUGMENTED\n",
        "            if imgs_processed % 50 == 0:\n",
        "                print(f\"processed {imgs_processed}/879\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "            continue\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    return images, masks"
      ],
      "metadata": {
        "id": "JI-zy1iX_KED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, masks = create_segmentation_dataset(label_array = [\"one\",\"five\",\"ten\",\"twenty\",\"fifty\",\"hundred\",\"money\",\"crop\"])"
      ],
      "metadata": {
        "id": "NoJnC5nRz-by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_and_masks(image, masks, label_array, img_num):\n",
        "    num_masks = masks.shape[-1]\n",
        "    total_plots = 1 + num_masks  # 1 for image + number of masks\n",
        "    cols = 3\n",
        "    rows = (total_plots + cols - 1) // cols  # Calculate required rows\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
        "    axes = axes.flatten()  # Flatten to easily index\n",
        "\n",
        "    # Plot the original image\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(f\"Original Image num{img_num}\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Plot each mask\n",
        "    for i in range(num_masks):\n",
        "        axes[i + 1].imshow(image)\n",
        "        axes[i + 1].imshow(masks[:, :, i], cmap=\"gray\", alpha=0.7)\n",
        "        axes[i + 1].set_title(f\"Mask: {label_array[i]}\")\n",
        "        axes[i + 1].axis(\"off\")\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for j in range(total_plots, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JKrCGsQBz-Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[1].shape"
      ],
      "metadata": {
        "id": "zoCNf1oJz-KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = random.randint(0, images.shape[0] - 1)\n",
        "sample_image = images[sample_index]\n",
        "sample_masks = masks[sample_index]\n",
        "plot_image_and_masks(sample_image, sample_masks, [\"one\",\"five\",\"ten\",\"twenty\",\"fifty\",\"hundred\",\"money\",\"crop\"],sample_index+1)"
      ],
      "metadata": {
        "id": "ro8XOo5A0Zw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "IMG_SIZE = 256          # make images same size\n",
        "BATCH_SIZE = 8          # 8 seems to be pretty standard\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 10             # can increase if needed\n",
        "BASE_FILTERS = 96\n",
        "LEARNING_RATE = 5e-4    # made a high learning rate, for quicker learning\n",
        "DROPOUT_RATE = 0.2      # dropout for some regularization\n",
        "L2_REG = 1e-4           # weight decay, tried various\n",
        "AUGMENT_DATA = False     # False, because we did it on our own, so we could see the image results and have greater control"
      ],
      "metadata": {
        "id": "P-OZNAAT0Zts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv_block(x, num_filters, dropout_rate=0.0):\n",
        "    # First Conv2D layer with L2 regularization\n",
        "    x = layers.Conv2D(filters=num_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\",\n",
        "                     kernel_regularizer=keras.regularizers.l2(L2_REG))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    # Second Conv2D layer\n",
        "    x = layers.Conv2D(filters=num_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "4UI8CgLg0Zqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(x, num_filters):\n",
        "    # x = # feature extraction (same H,W)\n",
        "    x = double_conv_block(x, num_filters, dropout_rate=DROPOUT_RATE)\n",
        "    # p = # downsample by 2\n",
        "    p = layers.MaxPooling2D(pool_size=(2, 2), padding=\"valid\")(x)\n",
        "\n",
        "    return x, p"
      ],
      "metadata": {
        "id": "6KyEDXFg0Zno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(x, skip, num_filters):\n",
        "    # x = # upsample (H,W) x2\n",
        "    x = layers.Conv2DTranspose(filters=num_filters, kernel_size=(3, 3), strides=2, padding=\"same\")(x)\n",
        "    # x = # fuse with encoder skip\n",
        "    x = layers.Concatenate()([x, skip])\n",
        "    # x = # refine features\n",
        "    x = double_conv_block(x, num_filters, dropout_rate=DROPOUT_RATE/2)  # Less dropout in decoder\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "OExvLoWt0ZkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_unet_1(input_shape=(256, 256, 3), base_num_filters=32, num_classes=1, final_act=None):\n",
        "    h, w, _ = input_shape\n",
        "    # multiples of 16 needed\n",
        "    assert h % 16 == 0 and w % 16 == 0\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    f1, p1 = encoder_block(inputs, base_num_filters)  # 256 -> 128\n",
        "    f2, p2 = encoder_block(p1, base_num_filters * 2) # 128 -> 64\n",
        "    f3, p3 = encoder_block(p2, base_num_filters * 4)# 64  -> 32\n",
        "    f4, p4 = encoder_block(p3, base_num_filters * 8) # 32  -> 16\n",
        "\n",
        "    # Bottleneck\n",
        "    bn = double_conv_block(p4, base_num_filters * 16, dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "    # Decoder\n",
        "    d4 = decoder_block(bn, f4, base_num_filters * 8)# 16 -> 32\n",
        "    d3 = decoder_block(d4, f3, base_num_filters * 4)# 32 -> 64\n",
        "    d2 = decoder_block(d3, f2, base_num_filters * 2)# 64 -> 128\n",
        "    d1 = decoder_block(d2, f1, base_num_filters)# 128 -> 256\n",
        "\n",
        "    # Head\n",
        "    act = final_act if final_act is not None else ('sigmoid' if num_classes == 1 else 'softmax')\n",
        "    outputs = layers.Conv2D(num_classes, 1, activation=act, padding='same')(d1)\n",
        "\n",
        "    return keras.Model(inputs, outputs, name='U-Net')"
      ],
      "metadata": {
        "id": "1-1KZoVZ0Zgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_money = make_unet_1(input_shape=(IMG_SIZE,IMG_SIZE,3), num_classes=1, final_act='sigmoid')"
      ],
      "metadata": {
        "id": "T3YIKZxN0yjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gets just the masks associated with the money.\n",
        "money_masks = masks[:,:,:,-2]"
      ],
      "metadata": {
        "id": "_3BdHakD0yg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = random.randint(0, images.shape[0] - 1)\n",
        "sample_image = images[sample_index]\n",
        "sample_money_mask = money_masks[sample_index]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(sample_image)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(sample_money_mask, cmap=\"gray\")\n",
        "plt.title(\"Money Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KxqguJOZ0yeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_money = tf.data.Dataset.from_tensor_slices((images, money_masks))\n",
        "dataset_money = dataset_money.shuffle(len(images), seed=21)\n",
        "\n",
        "val_split = 0.15\n",
        "val_size = int(len(images) * val_split)\n",
        "train_size = len(images)- val_size\n",
        "\n",
        "train_dataset_money = dataset_money.skip(val_size).batch(BATCH_SIZE)\n",
        "val_dataset_money = dataset_money.take(val_size).batch(BATCH_SIZE)\n",
        "print(f\"Train samples: {train_size}, Val samples: {val_size}\")\n"
      ],
      "metadata": {
        "id": "mR9nqbnt0ybI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
        "dataset = dataset.shuffle(len(images), seed=21)\n",
        "\n",
        "val_split = 0.2\n",
        "val_size = int(len(images) * val_split)\n",
        "train_size = len(images)- val_size\n",
        "\n",
        "train_dataset = dataset.skip(val_size).batch(BATCH_SIZE)\n",
        "val_dataset = dataset.take(val_size).batch(BATCH_SIZE)\n",
        "print(f\"Train samples: {train_size}, Val samples: {val_size}\")\n"
      ],
      "metadata": {
        "id": "5dvemDwX0yVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_money.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy', #might want to retry dice loss/combined loss\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "8Znpv5Dq1Vzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_money = model_money.fit(\n",
        "            train_dataset_money,\n",
        "            validation_data=val_dataset_money,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "\n",
        "        )"
      ],
      "metadata": {
        "id": "FSmVH3fs1Vuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(hist, log_scale=False):\n",
        "  plt.figure(figsize=(8,5))\n",
        "  plt.plot(hist.history[\"loss\"], color=\"blue\", linestyle=\"-\", label=\"train\")\n",
        "  plt.plot(hist.history[\"val_loss\"], color=\"red\", linestyle=\"--\", label=\"val\")\n",
        "\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Training vs Validation Loss\")\n",
        "  plt.legend()\n",
        "  plt.grid(True, which=\"both\", ls=\":\")\n",
        "  if log_scale:\n",
        "      plt.yscale(\"log\")\n",
        "      plt.ylabel(\"Loss (log scale)\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5B-bqd7e2l9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history_money)"
      ],
      "metadata": {
        "id": "GbFTwoQW1VmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions_grid(images, masks, preds=None, num_samples=9):\n",
        "    n = min(num_samples, len(images))\n",
        "    cols = 3 if preds is not None else 2\n",
        "    fig, axes = plt.subplots(nrows=n, ncols=cols, figsize=(5*cols, 3*n))\n",
        "\n",
        "    for idx in range(num_samples):\n",
        "        imag = images[idx]\n",
        "        mask = masks[idx]\n",
        "        pred  = preds[idx] if preds is not None else None\n",
        "\n",
        "        # Original Image\n",
        "        axes[idx, 0].set_title(\"Image\")\n",
        "        axes[idx, 0].imshow(imag)\n",
        "        axes[idx, 0].axis(\"off\")\n",
        "\n",
        "        # Ground Truth Mask\n",
        "        axes[idx, 1].set_title(\"Ground Truth Mask\")\n",
        "        axes[idx, 1].imshow(imag)\n",
        "        axes[idx, 1].imshow(mask, cmap=\"grey\", alpha=0.7)\n",
        "        axes[idx, 1].axis(\"off\")\n",
        "\n",
        "        # Predicted Mask\n",
        "        if preds is not None:\n",
        "            axes[idx, 2].set_title(\"Predicted Mask\")\n",
        "            axes[idx, 2].imshow(imag)\n",
        "            axes[idx, 2].imshow(pred, cmap=\"grey\", alpha=0.7)\n",
        "            axes[idx, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JeVbT5nO2qIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_samp_money, masks_samp_money = next(iter(train_dataset_money))\n",
        "preds = model_money.predict(images_samp_money)\n",
        "preds = (preds > 0.6).astype(\"float32\")  # threshold for binary mask, this we were tweaking and working with the find best 0.6 worked best\n",
        "\n",
        "plot_predictions_grid(images_samp_money, masks_samp_money, preds, num_samples=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "oeZQ1CCN_N4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3sowuTDm46aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cCxsBEw5jwSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating masks"
      ],
      "metadata": {
        "id": "H16OwDG0j0K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2M_lYdW5OVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkbvVJGe5TZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6Pi0u-q5UwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zd9KyBFX5alg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jh4vT5jK5aii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End creating masks and iamges"
      ],
      "metadata": {
        "id": "iqgBHgmikwS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with loading data"
      ],
      "metadata": {
        "id": "E0Wpej3Q6YrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAf17FHL5ae8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End loading data"
      ],
      "metadata": {
        "id": "brsVmewK6yvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start building UNET"
      ],
      "metadata": {
        "id": "1XiO85FX64xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZePxJWE5aUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaLkgF4C5lc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4rXSlgx5Usq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLk5XfLD5Uo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVsoWAMT5Uja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDaQCxGd5UXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QeGwZ6l7Q-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_k1ghZsE7QyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhTmRqpi7QnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End creating UNET"
      ],
      "metadata": {
        "id": "4ecLX9Ej69nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start train model"
      ],
      "metadata": {
        "id": "PET7Qtjc7bNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVmhjmX97bI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End train model"
      ],
      "metadata": {
        "id": "l8-0tZcF7a3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XgtH3r4D5NMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating file structure (YOLO vs ViT)"
      ],
      "metadata": {
        "id": "u3K4X1zSkwJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# end creating file structure"
      ],
      "metadata": {
        "id": "vSTgSndZk98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Example: 256x256 RGB images\n",
        "input_shape = (256, 256, 3)\n",
        "num_classes = 3  # change this to your number of classes\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')  # for multi-class\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',   # use 'binary_crossentropy' + Dense(1, sigmoid) for binary\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "w0pT1cSM0OHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Results"
      ],
      "metadata": {
        "id": "tck-ejERrabE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start visualizations"
      ],
      "metadata": {
        "id": "KRj1Amg9rLo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(hist, log_scale=False):\n",
        "  plt.figure(figsize=(8,5))\n",
        "  plt.plot(hist.history[\"loss\"], color=\"blue\", linestyle=\"-\", label=\"train\")\n",
        "  plt.plot(hist.history[\"val_loss\"], color=\"red\", linestyle=\"--\", label=\"val\")\n",
        "\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Training vs Validation Loss\")\n",
        "  plt.legend()\n",
        "  plt.grid(True, which=\"both\", ls=\":\")\n",
        "  if log_scale:\n",
        "      plt.yscale(\"log\")\n",
        "      plt.ylabel(\"Loss (log scale)\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "EnatPazb7odM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "_SOswDzE7oYV",
        "outputId": "1d454f03-7528-40e6-e426-dd52d8150d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1703789770.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test data\n",
        "test_images, test_masks = next(iter(val_dataset))\n",
        "test_predictions = model.predict(test_images)\n",
        "test_predictions_binary = (test_predictions > 0.95).astype(\"float32\")  # I tried various thresholds...\n",
        "# could tweak this more 0.95 is high, but seems to work should try on more images, ie our test images that we didn't train the model on\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "qXtJNMsC7oQR",
        "outputId": "0f2414a8-6291-492e-c002-52b0c032c5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2803091047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get a batch of test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_predictions_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# I tried various thresholds...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# could tweak this more 0.95 is high, but seems to work should try on more images, ie our test images that we didn't train the model on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    \"\"\"Calculate Intersection over Union (IoU) for binary masks\"\"\"\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
        "\n",
        "    if union == 0:\n",
        "        return 1.0 if intersection == 0 else 0.0\n",
        "    return intersection / union\n",
        "\n",
        "# Calculate IoU for each sample in the batch\n",
        "ious = []\n",
        "for i in range(len(test_images)):\n",
        "    iou = calculate_iou(test_masks[i].numpy(), test_predictions_binary[i])\n",
        "    ious.append(iou)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "lg8YwmlB8KjO",
        "outputId": "7c93026a-9001-4dcf-8a2d-b2a2bac1d3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1682565342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Calculate IoU for each sample in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions_binary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_segmentation_results(images, true_masks, pred_masks, num_samples=6):\n",
        "    \"\"\"Plot comparison of original images, true masks, and predicted masks\"\"\"\n",
        "    n = min(num_samples, len(images))\n",
        "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(15, 3*n))\n",
        "\n",
        "    for i in range(n):\n",
        "        img = images[i].numpy()\n",
        "        true_mask = np.squeeze(true_masks[i].numpy())\n",
        "        pred_mask = np.squeeze(pred_masks[i])\n",
        "\n",
        "        # Original Image\n",
        "        axes[i, 0].imshow(img)\n",
        "        axes[i, 0].set_title(f\"Original Image {i+1}\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        # True Mask Overlay\n",
        "        axes[i, 1].imshow(img)\n",
        "        axes[i, 1].imshow(true_mask, cmap=\"Reds\", alpha=0.5)\n",
        "        axes[i, 1].set_title(f\"True Mask {i+1}\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        # Predicted Mask Overlay\n",
        "        axes[i, 2].imshow(img)\n",
        "        axes[i, 2].imshow(pred_mask, cmap=\"Blues\", alpha=0.5)\n",
        "        axes[i, 2].set_title(f\"Predicted Mask {i+1}\\nIoU: {ious[i]:.3f}\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u-tFZjQ58MqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test data\n",
        "test_images, test_masks = next(iter(val_dataset))\n",
        "test_predictions = model.predict(test_images)\n",
        "test_predictions_binary = (test_predictions > 0.95).astype(\"float32\")  # Use better threshold\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "X4qpACYd9Dkh",
        "outputId": "3bbf100a-b490-4288-b616-876eeb2b0478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-540711674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get a batch of test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_predictions_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use better threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_segmentation_results(test_images, test_masks, test_predictions_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "fWS2pQa59FTe",
        "outputId": "a73fff23-3095-4905-d246-214b47b628a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1022978108.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_segmentation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pl9Ozm4T9HAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}